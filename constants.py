MODELS_LIST =  ['text-davinci-003',
                'code-davinci-002',
                'code-cushman-001',          
                'text-curie-001',
                'text-babbage-001',
                'text-ada-001']


FILE_TYPES_LIST =  ['txt','sql','py']


INPUT_HELP_TEXT = '''Начните набирать текст для отправки ИИ\n (количество символов не более 2024). \n
Или выберете один из примеров из списка Snippets и отредактируйте его.\n
Может загрузить текст или код из файла, \nесли символов больше 2024 текст будет обрезан.\n
После того как вы будете готовы нажмите кнопку Отправить ИИ \nили воспользуйтесь кнопками готовых вопросов подробнее см. в инструкции.
 '''

def help_dict(key):
    d= {'temperature':'Какую температуру выборки использовать, от 0 до 1. Более высокие значения, такие как 0,8, сделают вывод более случайным, а более низкие значения, такие как 0,2, сделают его более сфокусированным и детерминированным.',
    'top_p': 'Альтернатива выборке с температурой, называемая выборкой ядра, где модель рассматривает результаты токенов с вероятностной массой top_p. Таким образом, 0,1 означает, что учитываются только токены, составляющие 10% наиболее вероятной массы.Обычно мы рекомендуем изменить это или, temperatureно не оба.',
    'presence_penalty':'Число от -2,0 до 2,0. Положительные значения штрафуют новые токены в зависимости от того, появляются ли они в тексте до сих пор, что увеличивает вероятность того, что модель будет говорить о новых темах.',
    'frequency_penalty':'Число от -2,0 до 2,0. Положительные значения штрафуют новые токены в зависимости от их текущей частоты в тексте, уменьшая вероятность того, что модель дословно повторит одну и ту же строку.',
    'best_of':'Генерирует best_of завершений на стороне сервера и возвращает «лучший» (тот, у которого самая высокая вероятность регистрации на токен)',
    'max_tokens':'Максимальное количество токенов, которое будет сгенерировано при завершении. Количество токенов вашего приглашения плюс max_tokens не может превышать длину контекста модели. Большинство моделей имеют длину контекста 2048 токенов (за исключением новейших моделей, которые поддерживают 4096).'}
    return d.get(key)

#https://github.com/ajaxorg/ace-builds/tree/master/src
LANGUAGES_SMALL = ["c_cpp", "csharp", "css", "dart", "django", "dockerfile", "gitignore", "html",
    "ini", "java", "javascript", "json", "json5", "kotlin", "latex", "lua",
    "markdown", "mysql", "nginx","perl", "pgsql", "php", "powershell", "python", "r", "sql",
    "sqlserver","svg", "swift", "toml","xml", "yaml"]

